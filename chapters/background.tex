%This is a narrative description of the general context within which your project fits. Depending on your particular project characteristics, you are required to include discussion of any or all of the following – previous related work; the work or objectives of a client; the essential principles of systems or techniques you are using.%
%All this narrative should be properly referenced to source material citations. Remember that a high class project will refer to background sources beyond just those on the Web. %

%In writing this section you should pay close attention to your audience and their prior knowledge of the subject(s) that you are discussing. You should assume that your reader is a student who has just completed the second year of your degree programme and can therefore assume that the reader is familiar with all topics taught up to the end of the second year. Anything that is needed to understand your project and its context but which has not been taught by the end of the second year of your degree should be discussed in this background section. %

%This section may include one or more of the following subsections. It is difficult to give prescriptive guidance on which subsections you should include as this depends on the nature of the project you are undertaking – you should discuss this with your supervisor.%
\chapter{Background}

%Problem Context:
%If your project involves significant work on a non-computing topic that is likely to be unfamiliar to most readers (e.g. linguistics, fluid dynamics) you should describe the important principles, concepts and terminology of that subject area in some detail. You will have had to learn these yourself in getting to grips with this unfamiliar topic and you should summarize what you learnt to enable the reader to understand your subsequent discussion on your project work and how this relates to the wider topic area.
\section{Problem Context}

The main focus of this project is to create a network degradation tool that can be used to simulate imperfect network conditions. To understand the goal better it is important to know what criteria reduce network quality.

Latency, packet loss and bandwidth are the main factors that distinguish between good and bad internet connections. Latency is the delay between sending a message and seeing its result. Packet loss is the percentage of packets that are lost in transmission, the higher the percentage, the more effect it has on the speed and stability of the network. Bandwidth, is the measure of how many bits/bytes are being transferred per second, the larger the bandwidth the more data can be transferred in less time, thus making the overall connection faster. A combination of favourable values from these criteria defines a good network connection. One way to visualise the throughput of a network connection is a download and upload and speed test, the result of these is measured in Mbps and can be used to quickly compare the speed of two connections, this will be used later to briefly show the degradation.

It is also necessary to mention the protocols that are to be used in the network simulation section. TCP \citep{TCP} and UDP \citep{UDP} are the transport layer protocols up for discussion. 

Other small signs of poor network conditions is Jitter and Error rate. Jitter is simply the variance in packet delays, this is normally a issue that exists in large packet switched networks, this is however not an issue in TCP/IP based communications because TCP protocol deals with these issues. However, VoIP (Voice over IP) that uses UDP as its transport level protocol is visibly degraded by heavy jitter. Error rate is the number of bit errors that have occurred in a data stream over a period of time. This can again effect UDP based communications heavily but the TCP protocol deals with these issues so remains relatively unaffected.

\comments{Talk about how TCP deals with jitter?}
\comments{Talk more about Packet Loss/Latency/Packet Loss maybe even about smaller signs of bad connection quality?}

\subsection{Protocols}
\subsubsection{Transport Control Protocol (TCP)}
TCP's main design choices are centred around reliability, where it has a few techniques designed to make sure packets arrive correctly. 

\begin{center}
	\includegraphics[scale=0.7]{TCP_header}
	\begin{figure}[h]
		\caption{TCP Header (RFC 793)}
	\end{figure}	
	
\end{center}

\subsubsection*{Initiating a connection}
The connection begins by being initiated with a series of signals where they are abbreviated as ACK (Acknowledgement) and SYN (Synchronise). The first computer begins by sending an packets with the SYN flag set, this starts the synchronization process. Then once the target computer receives this SYN packet it sends back and ACK for that SYN and its own SYN to the initiating computer, so as a ACK + SYN packet, where finally the initial computer sends back an ACK packet for the previous SYN packet, this connection has now been initiated and the communication channel has been set up. This process is known as a `3-way handshake'.

For TCP to remain reliable it needs to maintain data on the status of a connection, where a connection is uniquely identified by the pair of sockets that define its two sides of the connection. The information retained contains, sequence number and window sizes where these values are used to calculate the expected next packet to therefore calculate if a packet has been retransmitted or if a packet has been send out of its order.

\begin{center}
	\includegraphics[scale=0.8]{SYN-ACK}
	\begin{figure}[h]
		\caption{The output from Wireshark showing the handshake}
	\end{figure}
\end{center}


\subsubsection*{Sequence Numbers and Acknowledgement Numbers}
One of the main mechanisms for detecting missing and incorrect packets is the sequence and acknowledgement numbers. The TCP design states that every octet (byte) will have a corresponding sequence number, this sequence number is then increased by the length of the data inside the packet, the length of a packet can be calculated by taking the total size of the packet and taking away the size of the header. For example, if a packet with a length of 100 was sent it would move the sequence value up by 100, this gives the protocol the information to judge what it should be expecting and what it has received, and if those two values don't add up an error has occurred. 

On the other side the sender needs to know it packets have been received, this is where the acknowledgement number comes in, packets carrying acknowledgements are known as ``ACKs". For a packet with a sequence number of 100 being sent will require a packet to be send back containing the ACK number of 100 to verify that is has been transferred correctly, an ACK packet is signified by the `ACK' flag in the packets header. If the ACK packet isn't received before the the time-out value has been reached the packet is resent, this is how TCP guarantees retransmission of packets and it's also one of the reasons why packet loss doesn't have the same effect it does on UDP with TCP.

In situations where connections are created and recreated quickly in succession or are being re-established after errors there cannot be sequence numbers that clash with previous segment that may still exist on a network connection, therefore TCP solves this issue by generating new initial sequence numbers using a Initial Sequence Number (ISN) generator that uses a 32 bit clock, this clock has a life cycle of 4.55 hours where this time period is commonly known as the Maximum Segment Lifetime (MSL) and if a ISN is generated within this time is can be guaranteed to be unique.

\subsubsection*{Receiving Window}
In the TCP header there is a two byte value that represents the receiving window size, this value defines the maximum size of unacknowledged packets the receiving end has space for. So if a client sends a packet with a 65535 window size value it tells the receiving computer not to send more than 65535 bytes before receiving corresponding acknowledgements. This value can also be extended using a value in the area allocated as the `TCP Options' called `windows scaling', this allows the value in the window size to be multiplied by this scale value. So, for example a window size of 65535 with a window scale of 5 would have a total window size of 327675 Bytes. This means that the larger the window the more data can be send before waiting is needed and can normally mean faster transfer speeds. Please note, this exchange of window scaling values is only performed in the handshake and can only be present in the initial exchange of packets.

\subsubsection*{Flow Control}
Flow controls is a mechanism used by the protocol to ensure that the receiving party does not become overwhelmed by the incoming transmission of packets. TCP has two types of buffers the `send' and `receive', where the send collects what data is going out and the receive collects what is coming in. This goal of the flow control is to prevent the sending of packets that will not fit in the destination receive buffer and therefore will prevent these packets from being dropped. The protocol achieves this by allowing each party to advertise its available receive buffer space through a this window size section in the header that was discussed previously. (This is included in each ACK packet). Once the receive buffer is full the receiving party will advertise what is known as a 'zero window' where it sets the Window size to `0' and transfer will stop until there is free space in the receive buffer.

\subsubsection*{Sliding Window}
To control the number of packets the protocol has in flight it utilises the `Sliding window. The size of the sliding window is altered by two factors: The size of the send buffer and the size of the destinations receive buffer, therefore the maximum amount of data the protocol can send is the smallest of the two previous values. The sliding window then dynamically works out how many packets it can send by working out the maximum data it can send while keeping track of the number of packets in flight (unacknowledged) and the current window size. This whole process gives the protocol the ability to dynamically adapt to changing conditions and prevent buffers from being overfilled the receiving end.


\subsubsection*{Congestion control}
When there are situations where multiple clients are connected to one receiver lets say a router for this example, the bandwidth needs to be split between the number of clients and this is performed by congestion controls. The clients send data and keep increasing their transfer rate until they discover packet loss, packet loss in this case is assumed to be a sign of congestion - this is because it thinks the packets are being lost because the router is dropping them due to insufficient packet buffering space. So as the number of clients requesting data from the router is reduced more bandwidth is freed up and available, the congestion algorithm is periodically probing the network to check for available bandwidth by increasing it transfer rate until packet loss is encountered where it then slows down and repeats the process. This results in TCP auto balancing when new clients are introduced and utilizing as much bandwidth as is available. Later this report will discuss the effects of packet loss, latency and other degradation signs on this congestion control.

\subsubsection*{Closing a connection}
The closing of a TCP connection is very similar to the initial construction of a TCP connection, but in this case the protocol utilises the `FIN' flag defined in the TCP header. In this example it will be a client disconnection from a server. After all the data is transferred the client no longer requires a connection to the server and sends an empty packet with the FIN bit send, the server receives the packet and returns an ACK. The server now sends its own FIN and this is then acknowledged by the client. This middle step with the server sending an ACK and FIN separately is performed in a single packet in live networks. The client and server not know the connection is closed and will free up any resources allocated to that connection.


\subsubsection{User Data Protocol (UDP)}
\begin{center}
	\includegraphics[scale=0.7]{udp_header}
	\begin{figure}[h]
		\caption{UDP Header (RFC 768)}
	\end{figure}		
\end{center}

UDP is by design the opposite of TCP and often you'll find the two protocols compared. UDP is often referred to as ``fire and forget" \citep{kempf2011thoughts} this is a short way of describing how UDP deals with packets. When a packet is to be sent UDP sends the packet and moves onto the next. However, this means aside from the checksum in the UDP header (A checksum can be used to check that the UDP data has been transferred correctly) there is zero error checking for the UDP protocol and results in UDP being considered unreliable in comparison to TCP. This lack of error-checking overhead however, greatly improves the speed of UDP protocols. UDP is not used in situations where communication is vital, but does find itself implemented in examples like voice or video chat because errors in these services are not catastrophic to operation and these imperfections can even go unnoticed. 
As the very small UDP header shows, it is a very simple protocol and is effectively a thin wrapper on top of the IP layer that allows for very quick transfers but with the cost of not guaranteed reliability, this is why packet loss effects UDP massively and the overall effect will be fully disused later.

\subsubsection{Address Resolution Protocol (ARP)}
The tool will be deployed either by having it run on a small custom computer set up to act as a router for the synthetic test network or by jumping between a user and an actual router on a live network. The program will achieve this jumping between a user and the router by utilising a long term vulnerability in the Address Resolution Protocol (ARP) \citep{arp2001}, before this is explained further it is first important to understand the relevant parts of a local network.

Each computer on a Local Area Network (LAN) has an IP assigned to it, this is the identifier on the local network, with this each computers wireless card has a MAC address, a MAC address is a unique identifier for a computer and is used to link up this non-unique local address (IP) to a real computer on a network, this combination of IP address and MAC address allow for the reuse of local IP numbers. The ARP protocol is therefore used to find out what MAC address is associated with a local IP address and visa versa. This is achieved via an entire network broadcast where computers that don't match ignore the ARP request, and the one being requested sends back a reply containing it's MAC address. Each computer maintains its own version of the arp data known as its 'ARP cache'.

An ARP packet is a very simple message format that contains an operation code that can either can be a request (1) or a response (2) where the packet also contains 4 addresses - 2 pairs of hardware and protocol addresses for the sender and target.

The ARP protocol contains no form of authentication verification meaning a malicious computer can send out faked custom ARP requests to change specific values in the routers ARP table, meaning a computer running this software can appear as the router to the victim, while also appearing as the victim to the router, thus having all the traffic between the two routed through the attacking computer. 

\begin{center}
\includegraphics[scale=0.7]{mitm}
	\begin{figure}[h]
		\caption{Photo depicting a MITM attack}
	\end{figure}
\end{center}

\subsubsection{Raspberry Pi}
As mentioned previously the effects will be performed on a custom computer acting as the router, because the network will be set-up to pass all traffic through this router, it will be able to simulate degradation on the entire networks traffic.
The Raspberry Pi \citep{upton2014raspberry} has been decided as the choice for the small custom computer. Originally designed to teach children to code on an inexpensive (less than £30) computer, the Pi has found itself involved in a multitude of uses ranging from NAS (Network Attached Server) to robot controllers. This is useful in this project due to its ease to set-up as a router, this is because of the easy access of low level aspects of the operating system due to it running a based OS. The Raspberry Pi will be run with its default Raspbian OS \citep{pi2014raspbian} that is built upon Debian \citep{murdock1994overview}. This is a optimised OS for the internal ARM CPU that allows the Raspberry Pi to run modern stripped down programs on its very limited hardware, where it will have plenty of power to easily handle traffic as a router.

%Comparison of Technologies:
%If there are several possible technologies that could be used in your project work you should present a comparative analysis and critical appraisal of each of these technologies. You should create a subsection for each of the technologies you discuss and title each subsection with the name of the technology it describes (e.g. object-oriented databases, XML ). Within each subsection you should provide an overview of the technology, its key features and its strengths and weaknesses in relation to your project.
\section{Comparison of Technologies}

\subsection{Protocol Comparison}
\subsubsection{TCP Based Protocols}

\subsubsection*{HTTP}
TCP has various protocols built on top of it. One of the most widely used protocols is HTTP/1.1 \citep{HTTP}. HTTP is a structured language used to transfer data worldwide. Its main use is the movement of web based data, this has been chosen as one of the protocols to be used in the test network to simulate live real-world traffic, this is due to the protocols heavy use in the real world. The protocol will be utilised by a web browser that attempts to access a web page, the degradation will therefore be visible through how quickly the web page loads and how responsive the connection seems.


\subsubsection*{FTP}
Another protocol based on top of TCP is FTP (File Transfer Protocol) \citep{FTP}, and as the broken down acronym suggests is the protocol used to transfer files across a network. This protocol has been selected also due to its integral use in a live network. It also has a quite intuitive way of representing the speed of a network through a download speed that is easy to understand for most users. The protocol will be tested with dummy files ranging from 1MB to 5GB. This size range was chosen to fully cover the normal spectrum of file size where it roughly ranges from a Word document to high quality video.

\subsubsection{Other TCP Considerations}

\subsubsection*{SFTP}
SFTP (SSH File Transfer Protocol) \citep{SFTP} was a consideration as a protocol to be used for the demonstration purposes. SFTP effectively is a secure version of FTP (but not to be mixed up with the Simple File Transfer Protocol). This was decided not to be used because of its added features such as authentication security does not fit within the scope of the project, and does not relate to network degradation. 

\subsubsection*{Mail based protocols}
Another widely used set of protocols are the email based family of protocols. SMTP (Simple Mail Transfer Protocol) is involved in the sending of mail, while examples like IMAP/POP are used for receiving mail. These protocols use TCP as their transport layer protocols. These protocols are fundamental to email functioning on the internet but visualisation into their degradation would be not different to that of bare TCP, the implementation of an email client would add unnecessary complexity while offering almost zero added value to the demonstrative purposes of this project.

\subsubsection{UDP Based Protocols}
UDP due to its speed but inherent unreliability, UDP is hugely affected by packet loss. Therefore, the effects on UDP has decided to be visualised by a program that simulates image transfer by assigning an individual UDP packet a number that corresponds to a single pixel, this packet is then sent. Once the server receives the packet, it reads the pixel number stored in the packet and changes that specific pixel to green. This creates a matrix of red (lost) and green(received) pixels. This therefore, gives a simple but effective visualisation of packet loss. 

\begin{center}
\includegraphics[scale=0.7]{UDP-Demo}
	\begin{figure}[h]
		\caption{Initial draft of the UDP user interface}
	\end{figure}
\end{center}

Other effects can also be performed on UDP to measure the degradation, latency and the arrival order of the packets are big signs of hostile transfer conditions. The monitoring of the latency and order can be performed by the UDP interface and could provide a much more detailed overview of the current health of the connection.

\subsection*{Other UDP based protocols}
UDP is used for situations where speed is required but reliability is not. Media streaming is a common example, lots of data need to arrive to the client quickly where missed frames when not too large can go unnoticed. This kind of implementation would be a huge overhead and even if a 3rd party application was used set-up and debugging would utilise time while providing not much more insight into what is happening to the protocol when degradation is high. This is why UDP had been left as bare boned as possible and the protocol has been left relatively exposed to allow an effective way to visualise the effects.


\subsection{Operating Systems}

\subsubsection{Linux}
Linux is the broad definition of a family of computer operating systems. The defining characteristics of a ``Linux" OS is the free and open source approach and the use of the Linux Kernel. Android for example has the largest market share in the mobile OS market \citep{share2015desktop}, Android utilises the Linux kernel as the centre for its operating system.

Linux was chosen for this project for its open source element that allows easy access to low-level features in the kernel. The section of the kernel that deals with the filtration of packets for uses like firewalls and packet sniffers is referred to as the ``NetFilter". This acts as an API of sorts where packets can be routed to the net-filter queue to await a verdict (accept or drop) before being moved on. This is the basis for the functionality of the program, it will run on the Raspberry Pi and route all packets that enter the box to the queue where the program will perform its effects on the packets. Latency for example is one of the simplest effect to simulate, the packet will be routed into the queue, taken out and stored and the delay between storing and accepting will be the set latency value and therefore simulating the effect of latency on that packet.

\subsubsection{Windows}
Linux was chosen over the other possible alternative; Windows. The Windows OS is distributed as closed source software under proprietary licences meaning to understand what is happening under the hood is far more difficult. The operating system is documented well and there is support for this form of functionality but due to the transparency of Linux, Linux was chosen as a 
more suitable alternative.   

Windows does however provide a solution to the packet filtering in the same way that NetFilter does, it's called Windows Filtering Platform (WFP) and it is a an API that allows access to the systems services in order to provide to create packet filtering application. Its functionality is very similar to that of NetFilter.

Windows however was not used because of the size of the Windows OS, below is the minimum system requirements for Windows 10 \footnote{\url{https://www.microsoft.com/en-US/windows/windows-10-specifications}}

%Windows Min System Requirements Table

\vspace{5mm} 
\begin{center}
\begin{tabular}{| l | l |}
	\hline
	Processor & 1 gigahertz (GHz) or faster processor or SoC \\
	RAM & 1 gigabyte (GB) for 32-bit or 2 GB for 64-bit \\
	Hard Disk Space & 16 GB for 32-bit OS 20 GB for 64-bit OS \\
	\hline
\end{tabular}
\vspace{5mm} 
\end{center}


This compared with the full Debian \footnote{\url{https://www.debian.org/releases/stable/i386/ch03s04.html.en}} OS that the striped down version of the Raspberry Pi's OS is based off:


\begin{center}
No Desktop\\
\vspace{1mm} 
\begin{tabular}{| l | l |}
	\hline
	Processor & 1GHZ Pentium 4 \\
	RAM & 128 MB \\
	Hard Disk Space & 2 GB \\
	\hline
\end{tabular}

\vspace{2.5mm}
With Desktop\\
\vspace{1mm}
\begin{tabular}{| l | l |}
	\hline
	Processor & 1GHZ Pentium 4 \\
	RAM & 512 MB \\
	Hard Disk Space & 10 GB \\
	\hline
\end{tabular}
\vspace{5mm}
\end{center}

The Raspberry Pi in this instance will be run without a monitor and on the command line so it will be without a desktop.

As you can see from the comparison above the Linux based OS has a much smaller set of requirements where RAM usage for example is 8 times smaller and therefore makes it more suited for this purpose.

%Alternative Solutions:
%If others have produced solutions or addressed similar problems to those addressed by your project you should describe those alternative solutions here. Similarly, if several possible approaches suggest themselves as ways of solving the problems inherent in your project you should discuss those here. You should provide a comparative analysis and critical appraisal of each alternative solution approach or existing solution, identifying their key features and their strengths and weaknesses in relation to your project.
\section{Alternative Solutions}

\comments{For all the solutions I need to be much more critical of the positives and negatives}

\subsection{clumsy}
A more modern application of network degradation is clumsy 0.2 \footnote{\url{http://jagt.github.io/clumsy/index.html}}. It provides various options (that can run in parallel) that effect network conditions. 

\begin{center}
	\includegraphics[scale=0.5]{clumsy}
	\begin{figure}[h]
		\caption{Main UI of clumsy}
	\end{figure}
\end{center}

The tool provides a way to affect network conditions. It solves issues involved with simulating harsh network conditions on a network. It does allow for filtering and has a couple of filter pre-sets, it however doesn't provide options to simulate live traffic and options to capture or visualise traffic is not part of the main package.

This tool provides and easy to use and simple tool, but only affects the traffic on the local machine, this is good for testing tools in the development stage of an application but cannot be used to simulate degradation across a simulated network.

\subsection{TMNetSim}
TMNetSim \footnote{\url{http://www.tmurgent.com/appv/en/87-tools/performance-tools/177-tmnetsim-quick-and-easy-network-simulation-tool}} is another tool that covers aspects of this project. Unlike clumsy TMNetSim is designed to provide degradation that expands over the network. However, to achieve this it has to be set-up on every machine, this is clunky and time consuming. The project being developed can negate this lengthy set-up with the intended inclusion of the ARP Spoofing. Further criticism relates to the ease of use of this application, it has a large number of controls on it's interface and will involve a larger learning curve to master compared to other simpler tools, this however might be the bi-product of more functionality; increased complexity.

This tool includes very complex ways of simulating realistic degradation with Gausian and ``Normal" delay modes, that attempt to provide more accurate representations of real-world delays. This is a great feature that could drastically improve the accuracy in simulating degradation and will need to be considered as an extra inclusion into this project.

%Comparison of Algotithms%
%There may be a number of different algorithms which could be applied to the central problems in your project and you have had to choose which of these algorithms are the most appropriate for your implementation. If this is the case then you should provide a comparative analysis and critical appraisal of each of the potentially applicable algorithms, highlighting their key features and their strengths and weaknesses in relation to your project.%
\section{Comparison of Algorithms}



%Process and Methodology%
%If your project is concerned with improving, implementing or evaluating a particular technical process or method of working you should discuss these in detail. We are not expecting you to describe what software development methodology you are following in implementing your project and you certainly do not need to regurgitate textbook descriptions of the Waterfall method here as everyone already knows that model well.%
\section{Process and Methodology}
